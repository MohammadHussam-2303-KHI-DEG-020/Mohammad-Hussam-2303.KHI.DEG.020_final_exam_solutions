{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import io \n",
    "import os\n",
    "import time\n",
    "import redis\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls end keys\n",
    "s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=os.environ.get(\"S3_ENDPOINT_URL\"),\n",
    "        aws_access_key_id=os.environ.get(\"MINIO_ROOT_USER\"),\n",
    "        aws_secret_access_key=os.environ.get(\"MINIO_ROOT_PASSWORD\"),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    current_time = datetime.now()\n",
    "    path = f\"year={current_time.year:04d}/month={current_time.month:02d}/day={current_time.day:02d}/hour={current_time.hour-1:02d}\"\n",
    "    response = s3.list_objects(Bucket=\"test-bucket\", Prefix=path)\n",
    "    dataframes = []\n",
    "\n",
    "    for obj in response[\"Contents\"]:\n",
    "        file_key = obj[\"Key\"]\n",
    "        if file_key.endswith(\".csv\"):\n",
    "            file_obj = s3.get_object(Bucket=\"test-bucket\", Key=obj[\"Key\"])\n",
    "            df = pd.read_csv(file_obj[\"Body\"])\n",
    "            dataframes.append(df)\n",
    "            \n",
    "    # Additional processing steps\n",
    "    processed_dataframes = []\n",
    "    for df in dataframes:\n",
    "        # Process each dataframe as needed\n",
    "        processed_df = process_dataframe(df)\n",
    "        processed_dataframes.append(processed_df)\n",
    "    \n",
    "    return processed_dataframes\n",
    "\n",
    "\n",
    "def process_dataframe(df):\n",
    "    # Example processing: calculate the sum of each column\n",
    "    column_sums = df.sum()\n",
    "    processed_df = pd.DataFrame({\"Column Sums\": column_sums}).transpose()\n",
    "    return processed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_postgress():\n",
    "    bookstore_data = pd.read_csv(\"../data/bookstore.csv\")\n",
    "    final_df = pd.merge(dfs, bookstore_data, on='ISBN-10', how='inner')\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_from_postgress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_to_redis():\n",
    "    redis_client = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
    "    redis_key = \"minio_files\"\n",
    "    redis_output = get_data_from_postgress()\n",
    "    \n",
    "    # Convert dataframe to JSON\n",
    "    redis_data = redis_output.to_json(orient=\"records\")\n",
    "    \n",
    "    # Store JSON data in Redis\n",
    "    redis_client.set(redis_key, redis_data)\n",
    "    \n",
    "    return redis_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_data():\n",
    "    transformed_df = load_to_redis()\n",
    "    transformed_df_1 = transformed_df.groupby([\"Format\", \"Language\"]).agg({\"Price\": [\"count\", \"sum\"]})\n",
    "    transformed_df_1.columns = [\"number_of_books_sold\", \"sale_values\"]\n",
    "    return transformed_df, transformed_df_1\n",
    "\n",
    "result_df, result_df_1 = transformed_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df, transformed_df_1 = transformed_data()\n",
    "\n",
    "# Calculate percentage of users who buy books in Spanish\n",
    "users = transformed_df[\"user_id\"].nunique()\n",
    "spanish_language_users = transformed_df[transformed_df.Language == \"Spanish\"][\"user_id\"].nunique()\n",
    "spanish_book_percentage = (spanish_language_users / users) * 100\n",
    "\n",
    "print(f\"Spanish Book Purchased by users in Percentage: {spanish_book_percentage:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"_main_\":\n",
    "    scheduler = BlockingScheduler()\n",
    "    scheduler.add_job(get_data(), 'interval', minutes=60)\n",
    "    scheduler.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
