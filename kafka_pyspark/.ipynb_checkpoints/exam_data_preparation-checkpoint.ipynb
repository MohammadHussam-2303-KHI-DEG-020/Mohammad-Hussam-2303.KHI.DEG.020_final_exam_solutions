{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefc9735-6789-46fd-9e0c-108f2b271cfa",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ea7c6c-c81d-4cad-a898-ff0a7ffb3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a472d2-e145-4cd0-b84e-5c15ed9764db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[1]\")\n",
    "    .appName(\"Exam data preparation\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2007450b-4f65-46d9-b300-fc9937e2f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.4.159:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Exam data preparation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe0ec432c50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b69f66",
   "metadata": {},
   "source": [
    "### Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda58200-409b-43c4-afbf-b71c332dab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landslides_schema = (\n",
    "    T.StructType()\n",
    "    .add(\"id\", T.StringType())\n",
    "    .add(\"date\", T.StringType())\n",
    "    .add(\"time\", T.StringType())\n",
    "    .add(\"country_code\", T.StringType())\n",
    "    .add(\"state/province\", T.StringType())\n",
    "    .add(\"population\", T.IntegerType())\n",
    "    .add(\"city/town\", T.StringType())\n",
    "    .add(\"distance\", T.FloatType())\n",
    "    .add(\"latitude\", T.FloatType())\n",
    "    .add(\"longitude\", T.FloatType())\n",
    "    .add(\"landslide_size\", T.StringType())\n",
    "    .add(\"injuries\", T.FloatType())\n",
    "    .add(\"fatalities\", T.FloatType())\n",
    ")\n",
    "\n",
    "df_source_batch_landslides = spark.read.parquet(\n",
    "    \"./data/landslides.parquet\", schema=landslides_schema\n",
    ")\n",
    "df_source_batch_landslides = df_source_batch_landslides.withColumn(\n",
    "    \"value\",\n",
    "    F.to_json(F.struct(*df_source_batch_landslides.columns)).cast(\n",
    "        T.StringType()\n",
    "    ),\n",
    ")\n",
    "dataframe_source_batch_writer_landslides = (\n",
    "    df_source_batch_landslides.select(\"value\")\n",
    "    .write.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"topic\", \"temp_topic\")\n",
    ")\n",
    "\n",
    "print(df_source_batch_landslides.select(\"value\").count())\n",
    "\n",
    "# Run twice to have duplicates to drop\n",
    "dataframe_source_batch_writer_landslides.save()\n",
    "dataframe_source_batch_writer_landslides.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34adda3-6a29-470f-b54c-9048e6d5f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "countries_schema = (\n",
    "    T.StructType()\n",
    "    .add(\"country_code\", T.StringType())\n",
    "    .add(\"country_name\", T.StringType())\n",
    ")\n",
    "\n",
    "df_source_batch_countries = spark.read.csv(\n",
    "    \"./data/countries.csv\", schema=countries_schema\n",
    ")\n",
    "df_source_batch_countries = df_source_batch_countries.withColumn(\n",
    "    \"value\",\n",
    "    F.to_json(F.struct(*df_source_batch_countries.columns)).cast(\n",
    "        T.StringType()\n",
    "    ),\n",
    ")\n",
    "dataframe_source_batch_writer_countries = (\n",
    "    df_source_batch_countries.select(\"value\")\n",
    "    .write.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"topic\", \"countries_topic\")\n",
    ")\n",
    "\n",
    "print(df_source_batch_countries.select(\"value\").count())\n",
    "\n",
    "dataframe_source_batch_writer_countries.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67114a-2246-40b3-952f-7b8c1812d34d",
   "metadata": {},
   "source": [
    "### Prepare landslides data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a29ab9-7455-42c7-a157-8ee9ca5286f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- distance: float (nullable = true)\n",
      " |-- landslide_size: string (nullable = true)\n",
      " |-- injuries: float (nullable = true)\n",
      " |-- fatalities: float (nullable = true)\n",
      " |-- location_columns: struct (nullable = false)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- state/province: string (nullable = true)\n",
      " |    |-- city/town: string (nullable = true)\n",
      " |    |-- population: integer (nullable = true)\n",
      " |    |-- latitude: float (nullable = true)\n",
      " |    |-- longitude: float (nullable = true)\n",
      " |-- time_columns: struct (nullable = false)\n",
      " |    |-- date: string (nullable = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- data_packed_for_kafka: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"temp_topic\")\n",
    "    .option(\"failOnDataLoss\", \"true\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"message_content\",\n",
    "    F.from_json(F.col(\"value\").cast(\"string\"), landslides_schema),\n",
    ")\n",
    "df_minimal = df.select(\"message_content.*\")\n",
    "\n",
    "location_columns = [\n",
    "    \"country_code\",\n",
    "    \"state/province\",\n",
    "    \"city/town\",\n",
    "    \"population\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "time_columns = [\"date\", \"time\"]\n",
    "df_to_kafka = df_minimal\n",
    "df_to_kafka = df_to_kafka.withColumn(\n",
    "    \"location_columns\", F.struct(location_columns)\n",
    ")\n",
    "df_to_kafka = df_to_kafka.withColumn(\"time_columns\", F.struct(time_columns))\n",
    "df_to_kafka = df_to_kafka.select(\n",
    "    \"id\",\n",
    "    \"distance\",\n",
    "    \"landslide_size\",\n",
    "    \"injuries\",\n",
    "    \"fatalities\",\n",
    "    \"location_columns\",\n",
    "    \"time_columns\",\n",
    ")\n",
    "df_to_kafka = df_to_kafka.withColumn(\n",
    "    \"data_packed_for_kafka\", F.to_json(F.struct(*df_to_kafka.columns))\n",
    ")\n",
    "df_to_kafka.printSchema()\n",
    "query = (\n",
    "    df_to_kafka.select(F.col(\"data_packed_for_kafka\").alias(\"value\"))\n",
    "    .write.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"topic\", \"landslides_topic\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015044a",
   "metadata": {},
   "source": [
    "Check for json correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24f15f-3dc6-4044-8ffe-5fe6cc8dc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meant_to_be_json = df_to_kafka.select(F.col(\"data_packed_for_kafka\")).tail(1)[\n",
    "    0\n",
    "][\"data_packed_for_kafka\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c79d2-7728-4b4d-8e4f-1da8a31789f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7541',\n",
       " 'distance': 1.78429,\n",
       " 'landslide_size': 'Small',\n",
       " 'injuries': 0.0,\n",
       " 'fatalities': 0.0,\n",
       " 'location_columns': {'country_code': 'US',\n",
       "  'state/province': 'Vermont',\n",
       "  'city/town': 'Windsor',\n",
       "  'population': 2066,\n",
       "  'latitude': 43.4771,\n",
       "  'longitude': -72.4066},\n",
       " 'time_columns': {'date': '3/2/16', 'time': '8:00'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# prove data is correctly formatted JSON\n",
    "json.loads(meant_to_be_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddeb5b4-a490-48d3-b5d5-e54ed13eb5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
